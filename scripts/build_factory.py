import json
import os
import subprocess
import sys
import concurrent.futures
import time
import re
import shutil

# --- é…ç½®åŒºåŸŸ ---
CONFIG_FILE = 'rules.json'
MAX_WORKERS = 5
GITHUB_STEP_SUMMARY = os.getenv('GITHUB_STEP_SUMMARY')

# è¾“å‡ºç›®å½•ç®¡ç†
DIR_SRS = "."         # SRS å­˜æ”¾ä½ç½® (æ ¹ç›®å½•)
DIR_JSON = "rules_json" # è°ƒè¯•ç”¨ JSON å­˜æ”¾ä½ç½®

# ä¸¥æ ¼æ˜ å°„è¡¨ (Clash/Surge -> Sing-box)
RULE_MAP = {
    'DOMAIN-SUFFIX': 'domain_suffix',
    'HOST-SUFFIX': 'domain_suffix',
    'DOMAIN': 'domain',
    'HOST': 'domain',
    'DOMAIN-KEYWORD': 'domain_keyword',
    'HOST-KEYWORD': 'domain_keyword',
    'IP-CIDR': 'ip_cidr',
    'IP-CIDR6': 'ip_cidr',
    'SRC-IP-CIDR': 'source_ip_cidr',
    'GEOIP': 'geoip',
    'DST-PORT': 'port',
    'SRC-PORT': 'source_port',
    'PROCESS-NAME': 'process_name'
}

class TaskResult:
    def __init__(self, name, status, msg, size="0KB"):
        self.name = name
        self.status = status
        self.msg = msg
        self.size = size

def setup_directories():
    """åˆå§‹åŒ–ç›®å½•"""
    if not os.path.exists(DIR_JSON):
        os.makedirs(DIR_JSON)

def get_core_version():
    core_path = "./sing-box"
    if not os.path.exists(core_path): return "âŒ æ ¸å¿ƒç¼ºå¤±"
    try:
        result = subprocess.run([core_path, "version"], capture_output=True, text=True, check=True)
        return result.stdout.split('\n')[0].split('version ')[-1].strip()
    except: return "â“ æœªçŸ¥ç‰ˆæœ¬"

def get_file_size(filepath):
    if not os.path.exists(filepath): return "0KB"
    size = os.path.getsize(filepath)
    for unit in ['B', 'KB', 'MB']:
        if size < 1024: return f"{size:.1f}{unit}"
        size /= 1024
    return f"{size:.1f}GB"

def download_file(url, filename):
    # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ UAï¼Œé˜²æ­¢åçˆ¬
    ua = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    cmd = ["curl", "-L", "--fail", "--retry", "3", "-A", ua, url, "-o", filename]
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        return True
    except subprocess.CalledProcessError:
        return False

# --- è¡¥å›çš„åŠŸèƒ½ï¼šå…¨å±€ JSON æ·±åº¦ä¼˜åŒ–ä¸å»é‡ ---
def optimize_json_file(filepath):
    """
    è¯»å– JSON æ–‡ä»¶ï¼Œå¯¹æ‰€æœ‰è§„åˆ™åˆ—è¡¨è¿›è¡Œå»é‡å’Œæ’åºï¼Œå¹¶é‡å†™æ–‡ä»¶ã€‚
    è¿”å›: (æ˜¯å¦ä¿®æ”¹è¿‡, ç§»é™¤çš„æ¡æ•°)
    """
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        rules = data.get('rules', [])
        total_removed = 0
        modified = False

        for rule in rules:
            for key, val in rule.items():
                if isinstance(val, list):
                    # ä½¿ç”¨ set å»é‡ï¼Œç„¶å sorted æ’åºä¿è¯ç¨³å®šæ€§
                    new_val = sorted(list(set(val)))
                    removed_count = len(val) - len(new_val)
                    
                    if removed_count > 0:
                        rule[key] = new_val
                        total_removed += removed_count
                        modified = True
        
        if modified:
            # é‡æ–°å†™å…¥ä¼˜åŒ–åçš„ JSON
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True, total_removed
        return False, 0
    except Exception as e:
        print(f"âš ï¸ ä¼˜åŒ– JSON å¤±è´¥: {e}")
        return False, 0

# --- æ ¸å¿ƒç»„ä»¶ 1: æ™ºèƒ½è½¬æ¢å™¨ ---
def convert_clash_to_json(input_file, output_json):
    """æ­£åˆ™æå–è§„åˆ™ -> è½¬æ¢ä¸º Sing-box JSON"""
    rules_dict = {v: set() for v in set(RULE_MAP.values())}
    count = 0
    
    try:
        with open(input_file, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
            
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#') or line.startswith('//'): continue
            
            # ç§»é™¤è¡Œå°¾æ³¨é‡Š
            line = re.split(r'\s*(#|//)', line)[0].strip()

            # æ­£åˆ™åŒ¹é…: ç±»å‹, å€¼
            match = re.search(r'^([A-Z0-9-]+)\s*,\s*([^,]+)', line, re.IGNORECASE)
            
            if match:
                raw_type = match.group(1).upper()
                value = match.group(2).strip().strip("'\"")
                
                if raw_type in RULE_MAP:
                    sb_type = RULE_MAP[raw_type]
                    rules_dict[sb_type].add(value)
                    count += 1

        if count == 0:
            return False, "æ— æœ‰æ•ˆè§„åˆ™"

        # æ„é€  JSON
        final_rules = []
        for k, v in rules_dict.items():
            if v:
                final_rules.append({k: sorted(list(v))})
        
        output_data = {"version": 3, "rules": final_rules}
        with open(output_json, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        return True, f"è½¬æ¢{count}æ¡"

    except Exception as e:
        return False, f"å¼‚å¸¸: {str(e)}"

# --- æ ¸å¿ƒç»„ä»¶ 2: éªŒè¯ä¸ç¼–è¯‘æµæ°´çº¿ ---
def decompile_srs(input_srs, output_json):
    """åç¼–è¯‘ SRS -> JSON"""
    cmd = ["./sing-box", "rule-set", "decompile", input_srs, "-o", output_json]
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        if os.path.getsize(output_json) < 10: return False
        return True
    except subprocess.CalledProcessError:
        return False

def compile_json(input_json, output_srs):
    """ç¼–è¯‘ JSON -> SRS (ä½¿ç”¨è‡ªå®šä¹‰æ ¸å¿ƒ)"""
    cmd = ["./sing-box", "rule-set", "compile", input_json, "-o", output_srs]
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        return True
    except subprocess.CalledProcessError:
        return False

def process_single_task(name, url):
    print(f"ğŸ”„ [{name}] å¯åŠ¨å¤„ç†...")
    
    temp_download = f"temp_raw_{name}"
    final_json = os.path.join(DIR_JSON, f"{name}.json")
    final_srs = os.path.join(DIR_SRS, f"{name}.srs")
    
    # 1. ä¸‹è½½
    if not download_file(url, temp_download):
        return TaskResult(name, "âŒ", "ä¸‹è½½å¤±è´¥")
    
    url_lower = url.lower()
    process_info = "æœªçŸ¥"
    json_ready = False
    
    # 2. ç”Ÿæˆæ ‡å‡† JSON (ä¸­é—´æ€)
    try:
        if url_lower.endswith('.srs'):
            print(f"ğŸ›¡ï¸ [{name}] æ­£åœ¨éªŒè¯ SRS å®Œæ•´æ€§...")
            if decompile_srs(temp_download, final_json):
                process_info = "SRSé‡æ„"
                json_ready = True
            else:
                return TaskResult(name, "âŒ", "SRSåç¼–è¯‘å¤±è´¥")
                
        elif url_lower.endswith('.json'):
            shutil.move(temp_download, final_json)
            process_info = "JSONåŸç”Ÿ"
            json_ready = True
            
        elif url_lower.endswith('.mrs'):
            return TaskResult(name, "âŒ", "ä¸æ”¯æŒMRSæ ¼å¼")
            
        else:
            print(f"ğŸ”§ [{name}] æ­£åœ¨è½¬æ¢è§„åˆ™æ ¼å¼...")
            success, msg = convert_clash_to_json(temp_download, final_json)
            if success:
                process_info = "æ ¼å¼è½¬æ¢"
                json_ready = True
            else:
                return TaskResult(name, "âŒ", f"è§£æå¤±è´¥: {msg}")

    except Exception as e:
         return TaskResult(name, "âŒ", f"å¤„ç†å¼‚å¸¸: {str(e)}")
    finally:
        if os.path.exists(temp_download): os.remove(temp_download)

    # 3. ä¼˜åŒ–ä¸ç¼–è¯‘ (Gatekeeper)
    if json_ready:
        # --- è¡¥å›çš„æ­¥éª¤ï¼šå¼ºåˆ¶æ‰§è¡Œå»é‡ä¼˜åŒ– ---
        is_opt, opt_count = optimize_json_file(final_json)
        if is_opt:
            print(f"âœ¨ [{name}] ä¼˜åŒ–å®Œæˆ: ç§»é™¤äº† {opt_count} æ¡é‡å¤è§„åˆ™")
            process_info += f"(å»é‡{opt_count})"
        # ---------------------------------

        if compile_json(final_json, final_srs):
            size = get_file_size(final_srs)
            print(f"âœ… [{name}] æˆåŠŸ: {process_info}")
            return TaskResult(name, "âœ…", f"{process_info}", size)
        else:
            print(f"âŒ [{name}] ç¼–è¯‘æ‹’ç»(JSONæ•°æ®ä¸åˆè§„)")
            return TaskResult(name, "âŒ", "ç¼–è¯‘æ‹’ç»(JSONéæ³•)")
            
    return TaskResult(name, "âŒ", "é€»è¾‘æœªçŸ¥é”™è¯¯")

def write_summary(results, core_ver):
    if not GITHUB_STEP_SUMMARY: return
    success_cnt = sum(1 for r in results if r.status == "âœ…")
    fail_cnt = len(results) - success_cnt
    
    with open(GITHUB_STEP_SUMMARY, 'a', encoding='utf-8') as f:
        f.write(f"## ğŸ­ è§„åˆ™å·¥å‚å®¡è®¡æŠ¥å‘Š\n")
        f.write(f"- **æ„å»ºæ ¸å¿ƒ**: `{core_ver}` (reF1nd)\n")
        f.write(f"- **ç»“æœç»Ÿè®¡**: âœ… {success_cnt} | âŒ {fail_cnt}\n")
        f.write(f"> ğŸ’¡ æºç å·²ç•™å­˜è‡³ `{DIR_JSON}/` (å·²æ‰§è¡Œè‡ªåŠ¨å»é‡ä¼˜åŒ–)ã€‚\n\n")
        f.write("| è§„åˆ™åç§° | çŠ¶æ€ | æµç¨‹è¯¦æƒ… | æ–‡ä»¶å¤§å° |\n|:---|:---:|:---|:---:|\n")
        for r in results: f.write(f"| **{r.name}** | {r.status} | {r.msg} | {r.size} |\n")

def main():
    print("ğŸš€ å¯åŠ¨ Sing-box å…¨èƒ½å·¥å‚ (Ultimate Fusion Edition)")
    setup_directories()
    
    core_ver = get_core_version()
    print(f"ğŸ’ æ ¸å¿ƒç‰ˆæœ¬: {core_ver}")
    if "âŒ" in core_ver: sys.exit(1)

    tasks = {}
    if len(sys.argv) == 3:
        tasks[sys.argv[1]] = sys.argv[2]
    elif os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r') as f:
                content = f.read().strip()
                if content: tasks = json.loads(content)
        except: pass

    if not tasks:
        print("â„¹ï¸ æ— ä»»åŠ¡")
        return

    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_single_task, n, u): n for n, u in tasks.items()}
        for future in concurrent.futures.as_completed(futures):
            results.append(future.result())

    write_summary(results, core_ver)
    if all(r.status == "âŒ" for r in results): sys.exit(1)

if __name__ == "__main__":
    main()
