name: Update Comprehensive SRS

on:
  workflow_dispatch:
  schedule:
    - cron: '0 20 * * *' # åŒ—äº¬æ—¶é—´å‡Œæ™¨ 4 ç‚¹è¿è¡Œ (UTC 20:00)
  push:
    paths:
      - 'fakeip-filter-Remote-DNS.json'
      - '.github/workflows/**'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          pip install dnspython requests

      - name: Install sing-box
        run: |
          LATEST_TAG=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep -Po '"tag_name": "\K.*?(?=")')
          VERSION_NUM=${LATEST_TAG#v}
          curl -Lo sing-box.tar.gz "https://github.com/SagerNet/sing-box/releases/download/${LATEST_TAG}/sing-box-${VERSION_NUM}-linux-amd64.tar.gz"
          tar -xvf sing-box.tar.gz
          mv sing-box-*/sing-box .
          chmod +x sing-box

      # ----------------------------------------------------------------
      # é˜¶æ®µ 1: ç”ŸæˆåŸºäºæƒé‡çš„åˆæ­¥ fakeip-filter.json
      # ----------------------------------------------------------------
      - name: Advanced Consensus Merge (FakeIP)
        run: |
          curl -sL "https://raw.githubusercontent.com/77160860/rule/refs/heads/main/filter.json" -o s1.json
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/fakeip-filter.srs" -o s2.srs
          ./sing-box rule-set decompile s2.srs -o s2.json
          curl -sL "https://raw.githubusercontent.com/HenryChiao/mihomo_yamls/refs/heads/main/custom/domain/fake-ip-filter.list" -o s3.list

          python3 -c "
          import json, re, os

          registry = {}

          def register(val, r_type, source_id):
              val = val.strip().lower()
              if not val or len(val) < 3 or ' ' in val or '/' in val or ':' in val: return
              if re.match(r'^\d{1,3}(\.\d{1,3}){3}$', val): return
              
              if val not in registry:
                  registry[val] = {'sources': set(), 'types': set()}
              registry[val]['sources'].add(source_id)
              registry[val]['types'].add(r_type)

          def load_json(path, sid):
              if not os.path.exists(path): return
              with open(path, 'r') as f:
                  data = json.load(f)
                  for r in data.get('rules', []):
                      for x in r.get('domain', []): register(x, 'domain', sid)
                      for x in r.get('domain_suffix', []): register(x, 'suffix', sid)
                      for x in r.get('domain_keyword', []): register(x, 'keyword', sid)

          load_json('s1.json', 'S1')
          load_json('s2.json', 'S2')

          if os.path.exists('s3.list'):
              with open('s3.list', 'r') as f:
                  for line in f:
                      line = line.strip()
                      if not line or line.startswith('#'): continue
                      if line.startswith('+.') or line.startswith('.'):
                          register(re.sub(r'^[+.]+', '', line), 'suffix', 'S3')
                      else:
                          register(line, 'domain', 'S3')

          final_rules = {'domain': [], 'domain_suffix': [], 'domain_keyword': [], 'domain_regex': []}
          
          for val, info in registry.items():
              if 'S1' in info['sources'] or len(info['sources']) >= 2:
                  if 'suffix' in info['types']: final_rules['domain_suffix'].append(val)
                  elif 'domain' in info['types']: final_rules['domain'].append(val)
                  elif 'keyword' in info['types']: final_rules['domain_keyword'].append(val)

          s_set = set(final_rules['domain_suffix'])
          final_rules['domain'] = [d for d in final_rules['domain'] if not any(d.endswith('.' + s) or d == s for s in s_set)]

          output = {'version': 3, 'rules': [{k: sorted(v) for k, v in final_rules.items() if v}]}
          with open('fakeip-filter.json', 'w') as f:
              json.dump(output, f, indent=2)
          "

      # ----------------------------------------------------------------
      # é˜¶æ®µ 2: åŠ¨æ€ IP å½’å±åœ°æ¸…æ´— + å¤šé‡é»‘åå•æ’é™¤ (CN / Private / Additional)
      # ----------------------------------------------------------------
      - name: Classify Domains (Advanced Five-Layer Filter)
        run: |
          # ä¸‹è½½æ‰€æœ‰æ’é™¤æº
          curl -sL "https://raw.githubusercontent.com/misakaio/chnroutes2/master/chnroutes.txt" -o chnroutes.txt
          curl -sL "https://raw.githubusercontent.com/MetaCubeX/meta-rules-dat/sing/geo/geosite/cn.json" -o geosite-cn.json
          
          # ä¸‹è½½æ‚¨è¦æ±‚çš„é¢å¤–æ’é™¤æº
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/private.srs" -o private.srs
          curl -sL "https://raw.githubusercontent.com/YiXuanZX/sing-box-geosite/main/rule/cn-additional-list-clash-classical.srs" -o cn-add.srs
          
          # åç¼–è¯‘ SRS åˆ° JSON
          ./sing-box rule-set decompile private.srs -o private.json
          ./sing-box rule-set decompile cn-add.srs -o cn-add.json

          python3 -c "
          import json, dns.resolver, ipaddress, concurrent.futures, os

          # 1. åŠ è½½ IP å½’å±åœ°æ•°æ®
          cn_networks = [ipaddress.ip_network(line.strip()) for line in open('chnroutes.txt') if line.strip() and not line.startswith('#')]
          
          # 2. åˆå¹¶é™æ€ç™½åå• (è¿™äº›åŸŸåå°†è¢«æ’é™¤åœ¨ Remote DNS åˆ—è¡¨ä¹‹å¤–)
          exclude_domains = set()

          def load_to_exclude(file_path):
              if not os.path.exists(file_path): return
              try:
                  with open(file_path, 'r') as f:
                      data = json.load(f)
                      for rule in data.get('rules', []):
                          for k in ['domain', 'domain_suffix']:
                              for d in rule.get(k, []): exclude_domains.add(d.lower())
              except Exception as e:
                  print(f'Error loading {file_path}: {e}')

          # åŠ è½½ä¸‰ä¸ªç™½åå•æ–‡ä»¶
          load_to_exclude('geosite-cn.json')
          load_to_exclude('private.json')
          load_to_exclude('cn-add.json')

          resolver = dns.resolver.Resolver()
          resolver.nameservers = ['8.8.8.8', '1.1.1.1']
          resolver.timeout = 1.5
          resolver.lifetime = 1.5

          def is_local(domain):
              domain = domain.lower()
              # å‡†åˆ™ A: é™æ€åç¼€æ’é™¤
              if domain.endswith('.cn') or domain.endswith('.local') or domain.endswith('.lan'): return True
              
              # å‡†åˆ™ B: é™æ€åˆ—è¡¨æ’é™¤ (CN/Private/Additional)
              parts = domain.split('.')
              for i in range(len(parts)):
                  if '.'.join(parts[i:]) in exclude_domains: return True
              
              # å‡†åˆ™ C: åŠ¨æ€è§£æ IP å½’å±åœ°åˆ¤å®š
              try:
                  answers = resolver.resolve(domain, 'A')
                  ip = ipaddress.ip_address(answers[0].to_text())
                  if ip.is_private: return True
                  return any(ip in net for net in cn_networks)
              except: return False

          with open('fakeip-filter.json', 'r') as f:
              data = json.load(f)
          
          all_domains = set()
          for r in data.get('rules', []):
              for k in ['domain', 'domain_suffix', 'domain_keyword']:
                  for d in r.get(k, []): all_domains.add(d)

          print(f'Filtering {len(all_domains)} domains against CN/Private/Additional lists...')
          
          remote_list = []
          with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:
              results = list(executor.map(lambda d: (d, is_local(d)), all_domains))
              remote_list = [d for d, local in results if not local]

          output_data = {'version': 3, 'rules': [{'domain_suffix': sorted(remote_list)}]}
          with open('fakeip-filter-Remote-DNS.json', 'w') as f:
              json.dump(output_data, f, indent=2)
          "
          ./sing-box rule-set compile fakeip-filter-Remote-DNS.json -o fakeip-filter-Remote-DNS.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 3: å¤„ç† WebRTC & å…¶ä»–
      # ----------------------------------------------------------------
      - name: Process WebRTC & Custom Rules
        run: |
          curl -sL "https://raw.githubusercontent.com/Kris-Channnn/sing-box-proxy/refs/heads/main/webRTC.json" -o raw_webrtc.json
          python3 -c "import json; f=open('raw_webrtc.json','r'); d=json.load(f); f.close(); open('webRTC.json','w').write(json.dumps({'version': 3, 'rules': d.get('rules', [])}, indent=2))"
          ./sing-box rule-set compile webRTC.json -o webRTC.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 4: æ¨é€ç»“æœ
      # ----------------------------------------------------------------
      - name: Push to Repo
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          
          # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¢åŠ äº† private.json å’Œ cn-add.json ç­‰ï¼‰
          rm -f s1.json s2.json s2.srs s3.list raw_webrtc.json sing-box sing-box.tar.gz 
          rm -f chnroutes.txt geosite-cn.json private.srs private.json cn-add.srs cn-add.json
          
          git add *.json *.srs
          
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "ğŸš€ Sync: Smart DNS Classification ($(date +'%Y-%m-%d'))"
            git push origin main --force
          fi
