name: Update Comprehensive SRS

on:
  workflow_dispatch:
  schedule:
    - cron: '0 20 * * *' # åŒ—äº¬æ—¶é—´å‡Œæ™¨ 4 ç‚¹è¿è¡Œ (UTC 20:00)
  push:
    paths:
      - 'fakeip-filter-Remote-DNS.json'
      - '.github/workflows/**'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          pip install dnspython requests

      - name: Install sing-box
        run: |
          LATEST_TAG=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep -Po '"tag_name": "\K.*?(?=")')
          VERSION_NUM=${LATEST_TAG#v}
          curl -Lo sing-box.tar.gz "https://github.com/SagerNet/sing-box/releases/download/${LATEST_TAG}/sing-box-${VERSION_NUM}-linux-amd64.tar.gz"
          tar -xvf sing-box.tar.gz
          mv sing-box-*/sing-box .
          chmod +x sing-box

      # ----------------------------------------------------------------
      # é˜¶æ®µ 1: åˆå¹¶åŸºç¡€ FakeIP åˆ—è¡¨
      # ----------------------------------------------------------------
      - name: Advanced Consensus Merge (FakeIP)
        run: |
          curl -sL "https://raw.githubusercontent.com/77160860/rule/refs/heads/main/filter.json" -o s1.json
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/fakeip-filter.srs" -o s2.srs
          ./sing-box rule-set decompile s2.srs -o s2.json
          curl -sL "https://raw.githubusercontent.com/HenryChiao/mihomo_yamls/refs/heads/main/custom/domain/fake-ip-filter.list" -o s3.list

          python3 -c "
          import json, re, os

          registry = {}

          def register(val, r_type, source_id):
              val = val.strip().lower()
              if not val or len(val) < 3 or ' ' in val or '/' in val or ':' in val: return
              if re.match(r'^\d{1,3}(\.\d{1,3}){3}$', val): return
              
              if val not in registry:
                  registry[val] = {'sources': set(), 'types': set()}
              registry[val]['sources'].add(source_id)
              registry[val]['types'].add(r_type)

          def load_json(path, sid):
              if not os.path.exists(path): return
              with open(path, 'r') as f:
                  data = json.load(f)
                  for r in data.get('rules', []):
                      for x in r.get('domain', []): register(x, 'domain', sid)
                      for x in r.get('domain_suffix', []): register(x, 'suffix', sid)
                      for x in r.get('domain_keyword', []): register(x, 'keyword', sid)
                      for x in r.get('domain_regex', []): register(x, 'regex', sid)

          load_json('s1.json', 'S1')
          load_json('s2.json', 'S2')

          if os.path.exists('s3.list'):
              with open('s3.list', 'r') as f:
                  for line in f:
                      line = line.strip()
                      if not line or line.startswith('#'): continue
                      if line.startswith('+.') or line.startswith('.'):
                          register(re.sub(r'^[+.]+', '', line), 'suffix', 'S3')
                      else:
                          register(line, 'domain', 'S3')

          final_rules = {'domain': [], 'domain_suffix': [], 'domain_keyword': [], 'domain_regex': []}
          
          for val, info in registry.items():
              if 'S1' in info['sources'] or len(info['sources']) >= 2:
                  if 'suffix' in info['types']: final_rules['domain_suffix'].append(val)
                  elif 'domain' in info['types']: final_rules['domain'].append(val)
                  elif 'keyword' in info['types']: final_rules['domain_keyword'].append(val)
                  elif 'regex' in info['types']: final_rules['domain_regex'].append(val)

          s_set = set(final_rules['domain_suffix'])
          final_rules['domain'] = [d for d in final_rules['domain'] if not any(d.endswith('.' + s) or d == s for s in s_set)]

          output = {'version': 3, 'rules': [{k: sorted(v) for k, v in final_rules.items() if v}]}
          with open('fakeip-filter.json', 'w') as f:
              json.dump(output, f, indent=2)
          "

      # ----------------------------------------------------------------
      # é˜¶æ®µ 2: åŠ¨æ€ IP å½’å±åœ°æ¸…æ´— & æ’é™¤ Private è§„åˆ™
      # ----------------------------------------------------------------
      - name: Classify Domains (Four-Layer Filter)
        run: |
          curl -sL "https://raw.githubusercontent.com/misakaio/chnroutes2/master/chnroutes.txt" -o chnroutes.txt
          curl -sL "https://raw.githubusercontent.com/MetaCubeX/meta-rules-dat/sing/geo/geosite/cn.json" -o geosite-cn.json
          # ä¸‹è½½ Private SRS å¹¶è§£å‹
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/private.srs" -o private.srs
          ./sing-box rule-set decompile private.srs -o private.json

          python3 -c "
          import json, dns.resolver, ipaddress, concurrent.futures, os

          # 1. åŠ è½½èµ„æº
          cn_networks = [ipaddress.ip_network(line.strip()) for line in open('chnroutes.txt') if line.strip() and not line.startswith('#')]
          
          def get_domains_from_json(path):
              d_set = set()
              if not os.path.exists(path): return d_set
              try:
                  with open(path, 'r') as f:
                      data = json.load(f)
                      for rule in data.get('rules', []):
                          for k in ['domain', 'domain_suffix']:
                              for d in rule.get(k, []): d_set.add(d)
              except: pass
              return d_set

          cn_domains_whitelist = get_domains_from_json('geosite-cn.json')
          private_domains = get_domains_from_json('private.json')

          resolver = dns.resolver.Resolver()
          resolver.nameservers = ['8.8.8.8', '1.1.1.1']
          resolver.timeout = 2.0
          resolver.lifetime = 2.0

          def is_excluded(domain):
              # A. æ’é™¤ Private (ç§æœ‰ç½‘ç»œ/å±€åŸŸç½‘)
              parts = domain.split('.')
              for i in range(len(parts)):
                  suffix = '.'.join(parts[i:])
                  if suffix in private_domains: return True

              # B. æ’é™¤ .cn åç¼€
              if domain.endswith('.cn'): return True
              
              # C. æ’é™¤ Geosite CN ç™½åå•
              for i in range(len(parts)):
                  suffix = '.'.join(parts[i:])
                  if suffix in cn_domains_whitelist: return True
              
              # D. åŠ¨æ€ DNS æ£€æŸ¥: æ˜¯å¦è§£æåˆ°ä¸­å›½å¤§é™† IP
              try:
                  answers = resolver.resolve(domain, 'A')
                  ip = ipaddress.ip_address(answers[0].to_text())
                  if any(ip in net for net in cn_networks): return True
              except: pass

              return False

          with open('fakeip-filter.json', 'r') as f:
              data = json.load(f)
          
          all_domains = set()
          for r in data.get('rules', []):
              for k in ['domain', 'domain_suffix', 'domain_keyword']:
                  for d in r.get(k, []): all_domains.add(d)

          print(f'Filtering {len(all_domains)} domains (Excluding Private & Local)...')
          
          # ç»“æœåˆ—è¡¨ï¼šåªæœ‰ä¸æ»¡è¶³ä¸Šè¿°æ‰€æœ‰æ’é™¤æ¡ä»¶çš„åŸŸåæ‰è¿›å…¥ Remote-DNS
          with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:
              results = list(executor.map(lambda d: (d, is_excluded(d)), all_domains))
              remote_list = [d for d, excluded in results if not excluded]

          output_data = {'version': 3, 'rules': [{'domain_suffix': sorted(remote_list)}]}
          with open('fakeip-filter-Remote-DNS.json', 'w') as f:
              json.dump(output_data, f, indent=2)
          "
          ./sing-box rule-set compile fakeip-filter-Remote-DNS.json -o fakeip-filter-Remote-DNS.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 3: å¤„ç† WebRTC & å…¶ä»–
      # ----------------------------------------------------------------
      - name: Process WebRTC
        run: |
          curl -sL "https://raw.githubusercontent.com/Kris-Channnn/sing-box-proxy/refs/heads/main/webRTC.json" -o raw_webrtc.json
          python3 -c "import json; f=open('raw_webrtc.json','r'); d=json.load(f); f.close(); open('webRTC.json','w').write(json.dumps({'version': 3, 'rules': d.get('rules', [])}, indent=2))"
          ./sing-box rule-set compile webRTC.json -o webRTC.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 4: æ¸…ç†å¹¶æ¨é€
      # ----------------------------------------------------------------
      - name: Push to Repo
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          
          rm -f s1.json s2.json s2.srs s3.list raw_webrtc.json sing-box sing-box.tar.gz 
          rm -f chnroutes.txt geosite-cn.json private.json private.srs
          
          git add *.json *.srs
          
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "ğŸš€ Sync: Optimized Remote-DNS (Excluded Private) ($(date +'%Y-%m-%d'))"
            git push origin main --force
          fi
