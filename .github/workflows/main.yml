name: Update Comprehensive SRS

on:
  workflow_dispatch:
  schedule:
    - cron: '0 20 * * *' # åŒ—äº¬æ—¶é—´å‡Œæ™¨ 4 ç‚¹è¿è¡Œ
  push:
    paths:
      - 'fakeip-filter-Remote-DNS.json'
      - '.github/workflows/**'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: pip install dnspython requests

      - name: Install sing-box
        run: |
          LATEST_TAG=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep -Po '"tag_name": "\K.*?(?=")')
          VERSION_NUM=${LATEST_TAG#v}
          curl -Lo sing-box.tar.gz "https://github.com/SagerNet/sing-box/releases/download/${LATEST_TAG}/sing-box-${VERSION_NUM}-linux-amd64.tar.gz"
          tar -xvf sing-box.tar.gz
          mv sing-box-*/sing-box .
          chmod +x sing-box

      # ----------------------------------------------------------------
      # é˜¶æ®µ 1: ç”ŸæˆåŸºç¡€ fakeip-filter.json (æƒé‡å…±è¯†)
      # ----------------------------------------------------------------
      - name: Advanced Consensus Merge (FakeIP)
        run: |
          # 1. ä¸‹è½½æº
          curl -sL "https://raw.githubusercontent.com/77160860/rule/refs/heads/main/filter.json" -o s1.json
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/fakeip-filter.srs" -o s2.srs
          ./sing-box rule-set decompile s2.srs -o s2.json
          curl -sL "https://raw.githubusercontent.com/HenryChiao/mihomo_yamls/refs/heads/main/custom/domain/fake-ip-filter.list" -o s3.list

          # 2. åˆå¹¶é€»è¾‘
          python3 -c "
          import json, re, os
          registry = {}
          
          def register(val, r_type, source_id):
              val = val.strip().lower()
              if not val or len(val) < 3 or ' ' in val: return
              if re.match(r'^\d{1,3}(\.\d{1,3}){3}$', val): return
              if val not in registry: registry[val] = {'sources': set(), 'types': set()}
              registry[val]['sources'].add(source_id)
              registry[val]['types'].add(r_type)

          def load_json(path, sid):
              if not os.path.exists(path): return
              with open(path, 'r') as f:
                  d = json.load(f)
                  for r in d.get('rules', []):
                      for x in r.get('domain', []): register(x, 'domain', sid)
                      for x in r.get('domain_suffix', []): register(x, 'suffix', sid)
                      for x in r.get('domain_keyword', []): register(x, 'keyword', sid)

          load_json('s1.json', 'S1')
          load_json('s2.json', 'S2')
          if os.path.exists('s3.list'):
              for line in open('s3.list'):
                  l = line.strip()
                  if l and not l.startswith('#'):
                      if l.startswith('.'): register(l.lstrip('.'), 'suffix', 'S3')
                      else: register(l, 'domain', 'S3')

          final = {'domain': [], 'domain_suffix': [], 'domain_keyword': []}
          for val, info in registry.items():
              if 'S1' in info['sources'] or len(info['sources']) >= 2:
                  # ç±»å‹ä¼˜å…ˆçº§ï¼šSuffix > Domain > Keyword
                  if 'suffix' in info['types']: final['domain_suffix'].append(val)
                  elif 'domain' in info['types']: final['domain'].append(val)
                  elif 'keyword' in info['types']: final['domain_keyword'].append(val)

          # åˆæ­¥å»é‡ï¼šå¦‚æœ suffix æ¶µç›–äº† domainï¼Œç§»é™¤ domain
          s_set = set(final['domain_suffix'])
          final['domain'] = [d for d in final['domain'] if not any(d.endswith('.' + s) or d == s for s in s_set)]

          with open('fakeip-filter.json', 'w') as f:
              json.dump({'version': 3, 'rules': [{k: sorted(v) for k, v in final.items() if v}]}, f, indent=2)
          "
          ./sing-box rule-set compile fakeip-filter.json -o fakeip-filter.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 2: æ™ºèƒ½åˆ†æµæ¸…æ´— (Remote vs Local) - å¢å¼ºç‰ˆ
      # ----------------------------------------------------------------
      - name: Classify Domains (Enhanced Filter)
        run: |
          # --- A. ä¸‹è½½ç™½åå•èµ„æº ---
          echo "Downloading White-lists..."
          # 1. IP è·¯ç”±è¡¨
          curl -sL "https://raw.githubusercontent.com/misakaio/chnroutes2/master/chnroutes.txt" -o chnroutes.txt
          # 2. Geosite CN
          curl -sL "https://raw.githubusercontent.com/MetaCubeX/meta-rules-dat/sing/geo/geosite/cn.json" -o geosite-cn.json
          # 3. Private è§„åˆ™ (å†…ç½‘/å±€åŸŸç½‘)
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/private.srs" -o private.srs
          ./sing-box rule-set decompile private.srs -o private.json
          # 4. CN Additional (è¡¥å……åˆ—è¡¨)
          curl -sL "https://raw.githubusercontent.com/YiXuanZX/sing-box-geosite/main/rule/cn-additional-list-clash-classical.srs" -o cn-add.srs
          ./sing-box rule-set decompile cn-add.srs -o cn-add.json

          # --- B. æ‰§è¡Œæ¸…æ´—è„šæœ¬ ---
          python3 -c "
          import json, dns.resolver, ipaddress, concurrent.futures, os

          # === 1. æ„å»º Local ç™½åå•åº“ ===
          print('Building Local Whitelist Database...')
          local_suffixes = set()
          local_exact_domains = set()

          def load_whitelist_json(path):
              if not os.path.exists(path): return
              try:
                  with open(path, 'r') as f:
                      d = json.load(f)
                      for r in d.get('rules', []):
                          for s in r.get('domain_suffix', []): local_suffixes.add(s.lower())
                          for d in r.get('domain', []): local_exact_domains.add(d.lower())
              except Exception as e:
                  print(f'Error loading {path}: {e}')

          # åŠ è½½ Geosite CN, Private, CN-Additional
          for p in ['geosite-cn.json', 'private.json', 'cn-add.json']:
              load_whitelist_json(p)

          # åŠ è½½ IP æ®µ
          cn_networks = []
          try:
              cn_networks = [ipaddress.ip_network(l.strip()) for l in open('chnroutes.txt') if l.strip() and not l.startswith('#')]
          except: pass
          
          print(f'Whitelist Loaded: {len(local_suffixes)} suffixes, {len(local_exact_domains)} exact domains.')

          # === 2. å®šä¹‰åˆ¤å®šé€»è¾‘ ===
          resolver = dns.resolver.Resolver()
          resolver.nameservers = ['8.8.8.8', '1.1.1.1'] # ä½¿ç”¨å›½é™… DNS é¿å…æ±¡æŸ“å¹²æ‰°åˆ¤æ–­
          resolver.timeout = 2.0
          resolver.lifetime = 2.0

          def is_domain_local_static(domain):
              domain = domain.lower().strip('.')
              # a. ç®€å•åç¼€
              if domain.endswith('.cn'): return True
              # b. ç²¾ç¡®åŒ¹é…
              if domain in local_exact_domains: return True
              # c. åç¼€æ ‘åŒ¹é… (é«˜æ•ˆ)
              # æ£€æŸ¥ domain åŠå…¶æ‰€æœ‰çˆ¶çº§æ˜¯å¦åœ¨ local_suffixes ä¸­
              # e.g. www.baidu.com -> check 'www.baidu.com', 'baidu.com', 'com'
              parts = domain.split('.')
              for i in range(len(parts)):
                  sub = '.'.join(parts[i:])
                  if sub in local_suffixes:
                      return True
              return False

          def resolve_ip_check(domain):
              try:
                  ans = resolver.resolve(domain, 'A')
                  ip_obj = ipaddress.ip_address(ans[0].to_text())
                  # å¦‚æœ IP åœ¨ CN æ®µå†…ï¼Œåˆ™æ˜¯ Local
                  for net in cn_networks:
                      if ip_obj in net: return True
                  return False
              except:
                  # è§£æå¤±è´¥é€šå¸¸æ„å‘³ç€è¢«å¢™æˆ–ä¸å­˜åœ¨ï¼Œä¸ºäº†ä¿é™©ï¼Œå½’ç±»ä¸º Remote
                  return False

          def classify(domain):
              # 1. é™æ€ç™½åå•ä¼˜å…ˆ (é€Ÿåº¦å¿«)
              if is_domain_local_static(domain): return (domain, True)
              # 2. åŠ¨æ€ IP åˆ¤å†³ (å…œåº•)
              is_local = resolve_ip_check(domain)
              return (domain, is_local)

          # === 3. ä¸»å¤„ç†æµç¨‹ ===
          with open('fakeip-filter.json', 'r') as f:
              source_data = json.load(f)

          # æå–å¾…åˆ†ç±»çš„æ‰€æœ‰åŸŸå
          candidates = {} # domain -> type
          for r in source_data.get('rules', []):
              for d in r.get('domain', []): candidates[d] = 'domain'
              for d in r.get('domain_suffix', []): candidates[d] = 'domain_suffix'
              # keyword å¾ˆéš¾ç²¾ç¡®åˆ¤æ–­ï¼Œæš‚ä¸å¤„ç†æˆ–ç›´æ¥è§†ä¸º Remoteï¼Œè¿™é‡Œæš‚ä¸”å¿½ç•¥ keyword é¿å…è¯¯ä¼¤

          print(f'Processing {len(candidates)} candidate domains...')
          
          final_remote = {'domain': [], 'domain_suffix': []}
          
          with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:
              future_map = {executor.submit(classify, d): (d, t) for d, t in candidates.items()}
              for future in concurrent.futures.as_completed(future_map):
                  d, t = future_map[future]
                  try:
                      _, is_local = future.result()
                      if not is_local:
                          # åªæœ‰é Local çš„æ‰æ”¾å…¥ Remote åˆ—è¡¨
                          if t == 'domain': final_remote['domain'].append(d)
                          else: final_remote['domain_suffix'].append(d)
                  except:
                      pass # å¿½ç•¥å¼‚å¸¸

          # === 4. æœ€ç»ˆå»é‡ä¼˜åŒ– ===
          # å¦‚æœ fakeip-filter é‡Œæ—¢æœ‰ suffix åˆæœ‰ domainï¼Œä¸”éƒ½åˆ¤å®šä¸º remoteï¼Œ
          # æ£€æŸ¥ domain æ˜¯å¦è¢« suffix è¦†ç›–
          rem_suffixes = set(final_remote['domain_suffix'])
          rem_domains = []
          for d in final_remote['domain']:
              # æ£€æŸ¥ d æ˜¯å¦æ˜¯ rem_suffixes ä¸­æŸé¡¹çš„å­åŸŸå
              is_covered = False
              parts = d.split('.')
              for i in range(len(parts)):
                  if '.'.join(parts[i:]) in rem_suffixes:
                      is_covered = True
                      break
              if not is_covered:
                  rem_domains.append(d)
          
          # è¾“å‡º
          output = {
              'version': 3, 
              'rules': [{
                  'domain': sorted(rem_domains),
                  'domain_suffix': sorted(list(rem_suffixes))
              }]
          }
          
          print(f'Final Remote Rules: {len(rem_domains)} domains, {len(rem_suffixes)} suffixes.')
          
          with open('fakeip-filter-Remote-DNS.json', 'w') as f:
              json.dump(output, f, indent=2)
          "
          
          ./sing-box rule-set compile fakeip-filter-Remote-DNS.json -o fakeip-filter-Remote-DNS.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 3: WebRTC & å…¶ä»–è¾…åŠ©
      # ----------------------------------------------------------------
      - name: Process WebRTC & Custom Rules
        run: |
          curl -sL "https://raw.githubusercontent.com/Kris-Channnn/sing-box-proxy/refs/heads/main/webRTC.json" -o raw_webrtc.json
          python3 -c "import json; d=json.load(open('raw_webrtc.json')); open('webRTC.json','w').write(json.dumps({'version': 3, 'rules': d.get('rules', [])}, indent=2))"
          ./sing-box rule-set compile webRTC.json -o webRTC.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 4: æäº¤ä¸æ¨é€
      # ----------------------------------------------------------------
      - name: Push to Repo
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          
          # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ (ä¿ç•™ç»“æœæ–‡ä»¶)
          rm -f s1.json s2.json s2.srs s3.list raw_webrtc.json \
                sing-box sing-box.tar.gz chnroutes.txt geosite-cn.json \
                private.srs private.json cn-add.srs cn-add.json
          
          git add *.json *.srs
          
          if git diff --staged --quiet; then
            echo "No changes detected."
          else
            git commit -m "ğŸš€ Sync: Smart DNS Rules (Added Private/CN-Add lists) ($(date +'%Y-%m-%d'))"
            git push origin main --force
          fi
