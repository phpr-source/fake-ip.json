name: Update Comprehensive SRS

on:
  workflow_dispatch:
  schedule:
    - cron: '0 20 * * *' 
  push:
    paths:
      - 'fakeip-filter-Remote-DNS.json'
      - '.github/workflows/**'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: pip install dnspython requests

      - name: Install sing-box
        run: |
          LATEST_TAG=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep -Po '"tag_name": "\K.*?(?=")')
          VERSION_NUM=${LATEST_TAG#v}
          curl -Lo sing-box.tar.gz "https://github.com/SagerNet/sing-box/releases/download/${LATEST_TAG}/sing-box-${VERSION_NUM}-linux-amd64.tar.gz"
          tar -xvf sing-box.tar.gz
          mv sing-box-*/sing-box .
          chmod +x sing-box

      - name: Advanced Merge & Smart Classification
        run: |
          # ä¸‹è½½æº
          curl -sL "https://raw.githubusercontent.com/77160860/rule/refs/heads/main/filter.json" -o s1.json
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/fakeip-filter.srs" -o s2.srs
          ./sing-box rule-set decompile s2.srs -o s2.json
          curl -sL "https://raw.githubusercontent.com/HenryChiao/mihomo_yamls/refs/heads/main/custom/domain/fake-ip-filter.list" -o s3.list
          
          # ä¸‹è½½åˆ†æµè¾…åŠ©æ•°æ®
          curl -sL "https://raw.githubusercontent.com/misakaio/chnroutes2/master/chnroutes.txt" -o chnroutes.txt
          curl -sL "https://raw.githubusercontent.com/MetaCubeX/meta-rules-dat/sing/geo/geosite/cn.json" -o geosite-cn.json

          python3 -c "
          import json, re, os, dns.resolver, ipaddress, concurrent.futures

          # --- 1. é…ç½®ä¸èµ„æºåŠ è½½ ---
          # æ”¶é›†æ‰€æœ‰è§„åˆ™ï¼Œä¸å†ä½¿ç”¨ sources è®¡æ•°è¿‡æ»¤ï¼Œæ”¹ä¸ºå¹¶é›†
          all_rules = {'domain': set(), 'domain_suffix': set(), 'domain_keyword': set()}
          
          LAN_SUFFIXES = {'.lan', '.local', '.home.arpa', '.internal', '.localdomain', 'localhost'}
          CN_NETWORKS = [ipaddress.ip_network(l.strip()) for l in open('chnroutes.txt') if l.strip() and not l.startswith('#')]
          
          CN_GEOSITE = set()
          try:
              with open('geosite-cn.json', 'r') as f:
                  g = json.load(f)
                  for r in g.get('rules', []):
                      for k in ['domain', 'domain_suffix']:
                          for d in r.get(k, []): CN_GEOSITE.add(d.lower())
          except: pass

          resolver = dns.resolver.Resolver()
          resolver.nameservers = ['8.8.8.8', '1.1.1.1']
          resolver.timeout = 1.5

          def register(val, r_type):
              val = val.strip().lower()
              if not val or len(val) < 3 or ' ' in val: return
              # æ’é™¤å±€åŸŸç½‘
              if any(val.endswith(s) or val == s.lstrip('.') for s in LAN_SUFFIXES): return
              
              if r_type == 'suffix': all_rules['domain_suffix'].add(val)
              elif r_type == 'keyword': all_rules['domain_keyword'].add(val)
              else: all_rules['domain'].add(val)

          # --- 2. åŠ è½½ä¸‰ä¸ªæ¥æº (æ— å·®åˆ«åˆå¹¶) ---
          # S1: åŸºå‡†æº
          if os.path.exists('s1.json'):
              d = json.load(open('s1.json'))
              for r in d.get('rules', []):
                  for x in r.get('domain', []): register(x, 'domain')
                  for x in r.get('domain_suffix', []): register(x, 'suffix')
                  for x in r.get('domain_keyword', []): register(x, 'keyword')

          # S2: è¡¥å……æº
          if os.path.exists('s2.json'):
              d = json.load(open('s2.json'))
              for r in d.get('rules', []):
                  for x in r.get('domain', []): register(x, 'domain')
                  for x in r.get('domain_suffix', []): register(x, 'suffix')
                  for x in r.get('domain_keyword', []): register(x, 'keyword')

          # S3: è¡¥å……æº
          if os.path.exists('s3.list'):
              for line in open('s3.list'):
                  line = line.strip()
                  if not line or line.startswith('#'): continue
                  if line.startswith('+.') or line.startswith('.'):
                      register(line.lstrip('+').lstrip('.'), 'suffix')
                  else:
                      register(line, 'domain')

          # --- 3. æ™ºèƒ½åˆ†æµåˆ¤å®š (ä»…é’ˆå¯¹ Remote DNS æ–‡ä»¶) ---
          def check_is_local(domain_info):
              val, r_type = domain_info
              if val.endswith('.cn'): return True
              # Geosite å‘½ä¸­
              parts = val.split('.')
              for i in range(len(parts)):
                  if '.'.join(parts[i:]) in CN_GEOSITE: return True
              # DNS åˆ¤å®š
              try:
                  ans = resolver.resolve(val, 'A')
                  ip = ipaddress.ip_address(ans[0].to_text())
                  return any(ip in net for net in CN_NETWORKS)
              except: return False

          # å‡†å¤‡å¾…æ£€æµ‹åˆ—è¡¨ (domain å’Œ domain_suffix éœ€è¦æ£€æµ‹ï¼Œkeyword é€šå¸¸ç›´æ¥æ”¾è¡Œæˆ–é»˜è®¤ Remote)
          to_check = []
          for d in all_rules['domain']: to_check.append((d, 'domain'))
          for d in all_rules['domain_suffix']: to_check.append((d, 'domain_suffix'))

          print(f'Total merged unique domains: {len(to_check)}. Starting DNS Cleaning...')
          
          remote_rules = {'domain': set(), 'domain_suffix': set(), 'domain_keyword': all_rules['domain_keyword']}
          
          with concurrent.futures.ThreadPoolExecutor(max_workers=30) as exe:
              results = list(exe.map(lambda x: (x, check_is_local(x)), to_check))
              for (val, r_type), is_local in results:
                  if not is_local:
                      remote_rules[r_type].add(val)

          # --- 4. æœ€ç»ˆå»é‡ä¸æ ¼å¼åŒ– ---
          def final_clean(rule_dict):
              suffixes = sorted(list(rule_dict['domain_suffix']), key=len)
              # å¦‚æœ domain è¢« domain_suffix åŒ…å«ï¼Œåˆ é™¤ domain
              clean_domains = [
                  d for d in rule_dict['domain'] 
                  if not any(d.endswith('.' + s) or d == s for s in suffixes)
              ]
              return {
                  'version': 3,
                  'rules': [{
                      'domain': sorted(clean_domains),
                      'domain_suffix': sorted(suffixes),
                      'domain_keyword': sorted(list(rule_dict['domain_keyword']))
                  }]
              }

          # ç”Ÿæˆ fakeip-filter.json (åŒ…å«æ‰€æœ‰æ¥æºçš„å¹¶é›†)
          all_output = final_clean(all_rules)
          with open('fakeip-filter.json', 'w') as f:
              json.dump(all_output, f, indent=2)

          # ç”Ÿæˆ fakeip-filter-Remote-DNS.json (å¹¶é›†ä¸­å±äºæµ·å¤–çš„éƒ¨åˆ†)
          remote_output = final_clean(remote_rules)
          with open('fakeip-filter-Remote-DNS.json', 'w') as f:
              json.dump(remote_output, f, indent=2)
          "
          
          # ç¼–è¯‘æˆ SRS
          ./sing-box rule-set compile fakeip-filter.json -o fakeip-filter.srs
          ./sing-box rule-set compile fakeip-filter-Remote-DNS.json -o fakeip-filter-Remote-DNS.srs

      - name: Process WebRTC & Extra
        run: |
          curl -sL "https://raw.githubusercontent.com/Kris-Channnn/sing-box-proxy/refs/heads/main/webRTC.json" -o raw_webrtc.json
          python3 -c "import json; d=json.load(open('raw_webrtc.json')); open('webRTC.json','w').write(json.dumps({'version': 3, 'rules': d.get('rules', [])}, indent=2))"
          ./sing-box rule-set compile webRTC.json -o webRTC.srs

      - name: Push to Repo
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          rm -f s1.json s2.json s2.srs s3.list raw_webrtc.json sing-box sing-box.tar.gz chnroutes.txt geosite-cn.json
          git add *.json *.srs
          if git diff --staged --quiet; then
            echo "No changes"
          else
            git commit -m "ğŸš€ Sync: Unified Combined Rules (S1 Base + S2/S3 Supp) ($(date +'%Y-%m-%d'))"
            git push origin main --force
          fi
