name: Update Comprehensive SRS

on:
  workflow_dispatch:
  schedule:
    - cron: '0 20 * * *' # åŒ—äº¬æ—¶é—´å‡Œæ™¨ 4 ç‚¹è¿è¡Œ
  push:
    paths:
      - '.github/workflows/**'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: pip install dnspython requests

      - name: Install sing-box
        run: |
          LATEST_TAG=$(curl -s "https://api.github.com/repos/SagerNet/sing-box/releases/latest" | grep -Po '"tag_name": "\K.*?(?=")')
          VERSION_NUM=${LATEST_TAG#v}
          curl -Lo sing-box.tar.gz "https://github.com/SagerNet/sing-box/releases/download/${LATEST_TAG}/sing-box-${VERSION_NUM}-linux-amd64.tar.gz"
          tar -xvf sing-box.tar.gz
          mv sing-box-*/sing-box .
          chmod +x sing-box

      # ----------------------------------------------------------------
      # é˜¶æ®µ 1: ä¸‰æºåˆå¹¶ (S1 å¿…ä¿, S2/S3 äº¤å‰å°è¯)
      # ----------------------------------------------------------------
      - name: Stage 1 - Consensus Merge
        run: |
          curl -sL "https://raw.githubusercontent.com/77160860/rule/refs/heads/main/filter.json" -o s1.json
          curl -sL "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/fakeip-filter.srs" -o s2.srs
          ./sing-box rule-set decompile s2.srs -o s2.json
          curl -sL "https://raw.githubusercontent.com/HenryChiao/mihomo_yamls/refs/heads/main/custom/domain/fake-ip-filter.list" -o s3.list

          python3 -c "
          import json, re, os
          registry = {} 

          def add_to_reg(val, r_type, src):
              if r_type != 'domain_regex': val = val.strip().lower()
              if not val: return
              key = (r_type, val)
              if key not in registry: registry[key] = set()
              registry[key].add(src)

          with open('s1.json', 'r') as f:
              d = json.load(f)
              for r in d.get('rules', []):
                  for k in ['domain', 'domain_suffix', 'domain_keyword', 'domain_regex']:
                      for v in r.get(k, []): add_to_reg(v, k, 'S1')

          with open('s2.json', 'r') as f:
              d = json.load(f)
              for r in d.get('rules', []):
                  for k in ['domain', 'domain_suffix', 'domain_keyword', 'domain_regex']:
                      for v in r.get(k, []): add_to_reg(v, k, 'S2')

          if os.path.exists('s3.list'):
              for line in open('s3.list'):
                  l = line.strip()
                  if not l or l.startswith('#'): continue
                  if l.startswith('.'): add_to_reg(l.lstrip('.'), 'domain_suffix', 'S3')
                  else: add_to_reg(l, 'domain', 'S3')

          final_rules = {'domain': [], 'domain_suffix': [], 'domain_keyword': [], 'domain_regex': []}
          for (r_type, val), sources in registry.items():
              if 'S1' in sources or ('S2' in sources and 'S3' in sources):
                  final_rules[r_type].append(val)

          output = {'version': 3, 'rules': [{k: sorted(v) for k, v in final_rules.items() if v}]}
          with open('fakeip-filter.json', 'w') as f:
              json.dump(output, f, indent=2)
          "
          ./sing-box rule-set compile fakeip-filter.json -o fakeip-filter.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 2: æ·±åº¦æ¸…æ´— (é›†æˆ Microsoft/Apple/Google/Games CN)
      # ----------------------------------------------------------------
      - name: Stage 2 - Deep Classification
        run: |
          # ä¸‹è½½æ‰€æœ‰å¿…è¦çš„ SRS èµ„æº
          urls=(
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/cn.srs"
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/private.srs"
            "https://raw.githubusercontent.com/YiXuanZX/sing-box-geosite/main/rule/cn-additional-list-clash-classical.srs"
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/microsoft-cn.srs"
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/apple-cn.srs"
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/google-cn.srs"
            "https://github.com/DustinWin/ruleset_geodata/releases/download/sing-box-ruleset/games-cn.srs"
          )
          
          for url in "${urls[@]}"; do
            filename=$(basename "$url")
            curl -sL "$url" -o "$filename"
            ./sing-box rule-set decompile "$filename" -o "${filename%.*}.json"
          done

          curl -sL "https://raw.githubusercontent.com/misakaio/chnroutes2/master/chnroutes.txt" -o chnroutes.txt

          python3 -c "
          import json, dns.resolver, ipaddress, concurrent.futures, os

          local_exact = set()
          local_suffix = set()
          
          def load_white(path):
              if not os.path.exists(path): return
              try:
                  with open(path, 'r') as f:
                      d = json.load(f)
                      for r in d.get('rules', []):
                          for x in r.get('domain', []): local_exact.add(x.lower())
                          for x in r.get('domain_suffix', []): local_suffix.add(x.lower())
              except: pass

          # åŠ è½½æ‰€æœ‰è§£å‹åçš„ç™½åå• JSON
          json_files = ['cn.json', 'private.json', 'cn-additional-list-clash-classical.json', 
                        'microsoft-cn.json', 'apple-cn.json', 'google-cn.json', 'games-cn.json']
          for p in json_files:
              load_white(p)

          cn_nets = [ipaddress.ip_network(l.strip()) for l in open('chnroutes.txt') if l.strip() and not l.startswith('#')]
          
          resolver = dns.resolver.Resolver()
          resolver.nameservers = ['8.8.8.8', '1.1.1.1']
          resolver.timeout = 1.5

          def check_is_local(domain):
              d = domain.lower().strip('.')
              if d.endswith('.cn'): return True
              if d in local_exact: return True
              parts = d.split('.')
              for i in range(len(parts)):
                  if '.'.join(parts[i:]) in local_suffix: return True
              try:
                  ans = resolver.resolve(d, 'A')
                  ip_obj = ipaddress.ip_address(ans[0].to_text())
                  if any(ip_obj in net for net in cn_nets): return True
              except: pass
              return False

          with open('fakeip-filter.json', 'r') as f:
              source = json.load(f)

          remote_rules = {'domain': [], 'domain_suffix': [], 'domain_keyword': [], 'domain_regex': []}
          rules_obj = source['rules'][0]
          
          # ä¿ç•™æ— æ³•é€šè¿‡ DNS åˆ¤å®šå½’å±åœ°çš„æ¨¡ç³Šè§„åˆ™
          remote_rules['domain_keyword'] = rules_obj.get('domain_keyword', [])
          remote_rules['domain_regex'] = rules_obj.get('domain_regex', [])

          to_check = []
          for d in rules_obj.get('domain', []): to_check.append((d, 'domain'))
          for d in rules_obj.get('domain_suffix', []): to_check.append((d, 'domain_suffix'))

          with concurrent.futures.ThreadPoolExecutor(max_workers=30) as exe:
              futures = {exe.submit(check_is_local, item[0]): item for item in to_check}
              for f in concurrent.futures.as_completed(futures):
                  domain, r_type = futures[f]
                  try:
                      if not f.result():
                          remote_rules[r_type].append(domain)
                  except:
                      remote_rules[r_type].append(domain) # å¼‚å¸¸åˆ™ä¿å®ˆä¿ç•™

          # æ·±åº¦å»é‡
          s_set = set(remote_rules['domain_suffix'])
          remote_rules['domain'] = [d for d in remote_rules['domain'] if not any(d.endswith('.' + s) or d == s for s in s_set)]

          with open('fakeip-filter-Remote-DNS.json', 'w') as f:
              json.dump({'version': 3, 'rules': [{k: sorted(v) for k, v in remote_rules.items() if v}]}, f, indent=2)
          "
          ./sing-box rule-set compile fakeip-filter-Remote-DNS.json -o fakeip-filter-Remote-DNS.srs

      # ----------------------------------------------------------------
      # é˜¶æ®µ 3: WebRTC å¤„ç†ä¸æ¸…ç†æ¨é€
      # ----------------------------------------------------------------
      - name: Stage 3 - Finalize
        run: |
          curl -sL "https://raw.githubusercontent.com/Kris-Channnn/sing-box-proxy/refs/heads/main/webRTC.json" -o raw_webrtc.json
          python3 -c "import json; d=json.load(open('raw_webrtc.json')); open('webRTC.json','w').write(json.dumps({'version': 3, 'rules': d.get('rules', [])}, indent=2))"
          ./sing-box rule-set compile webRTC.json -o webRTC.srs

          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          
          # æ™ºèƒ½æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
          find . -name "*.srs" ! -name "fakeip-filter.srs" ! -name "fakeip-filter-Remote-DNS.srs" ! -name "webRTC.srs" -delete
          find . -name "*.json" ! -name "fakeip-filter.json" ! -name "fakeip-filter-Remote-DNS.json" ! -name "webRTC.json" -delete
          rm -f s3.list chnroutes.txt sing-box sing-box.tar.gz
          
          git add *.json *.srs
          if git diff --staged --quiet; then
            echo "No changes"
          else
            git commit -m "ğŸš€ Sync: Weighted Merge & Multi-CN Static Filter ($(date +'%Y-%m-%d'))"
            git push origin main --force
          fi
